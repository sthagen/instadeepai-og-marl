{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv3wzEhCFIYI"
      },
      "source": [
        "# Dataset API Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This simple notebook demonstrates how to use OG-MARL's dataset API, which is underpinned by [Flashbax](https://github.com/instadeepai/flashbax)'s Vault utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this example, we'll download the `3m` dataset from the `smac_v1` environment. The zipped file is about 1.3GB in size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s56Pc_0mEMnr",
        "outputId": "ec588e7d-63b5-488d-9356-6817321c0e72"
      },
      "outputs": [],
      "source": [
        "!wget https://s3.kao.instadeep.io/offline-marl-dataset/vaults/3m.zip --show-progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BCKg-mgrJSY3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip 3m.zip -d vaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We should now have a directory of `vaults`, containing the `3m.vlt` vault, which itself contains 3 datasets: `Good`, `Medium`, and `Poor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -la vaults/3m.vlt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll take a look at the `Good` dataset in this example, but the methodology will apply to any of OG-MARL's Vault-style datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before continuing, we need to install Flashbax, which is the only necessary dependency. For our example, we'll also use `jax` and `jax.numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "exaixAhwJoas"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install flashbax~=0.1.2\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flashbax as fbx\n",
        "from flashbax.vault import Vault"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can load in the Vault. Notice the keyword arguments, and how they map to the dataset location: `rel_dir` is the root directory of all vaults; `vault_name` is the set of vaults coming from one environment; `vault_uid` is the unique identifier of each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGOzZuo2KC7f",
        "outputId": "9b3640de-2fb5-4be0-bb44-9302e631fa9e"
      },
      "outputs": [],
      "source": [
        "vlt = Vault(rel_dir=\"vaults\", vault_name=\"3m.vlt\", vault_uid=\"Good\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can read this Vault using `.read()`. By default, we read the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UaKlN9vLKEhM"
      },
      "outputs": [],
      "source": [
        "all_data = vlt.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The read data is in the structure of a `TrajectoryBufferState` from Flashbax, with auxiliary fields `.current_index` and `.is_full`. For our example, let's just look at `.experience`, containing the experience data itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "U1CBl6SOKfh8"
      },
      "outputs": [],
      "source": [
        "offline_data = all_data.experience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the structure of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzn-HovwKoP0",
        "outputId": "e0d52375-7cd1-4854-886e-4a0826dd9a2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'actions': (1, 996366, 3),\n",
              " 'infos': {'legals': (1, 996366, 3, 9), 'state': (1, 996366, 48)},\n",
              " 'observations': (1, 996366, 3, 30),\n",
              " 'rewards': (1, 996366, 3),\n",
              " 'terminals': (1, 996366, 3),\n",
              " 'truncations': (1, 996366, 3)}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.tree_map(lambda x: x.shape, offline_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This data is stored with the shapes of: $(B, T, N, *E)$, where $B$ is a stored batch dimension (useful for the synchronous storage of independent trajectories), $T$ is the time-axis of the data, $N$ is the number of agents, and $*E$ represents the one or more experience dimensions. e.g. For `observations`, we have `996366` timesteps from `3` agents, each with an observation of size `30`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As another illustrative example, let's look at the first `25` timesteps of the `terminals`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMVP1PTYK0NZ",
        "outputId": "b478e893-4b3b-4c67-8f0e-c7656490a087"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]]], dtype=float32)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "offline_data['terminals'][:, 0:25, ...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see the 20th timestep has an array of terminals, `[1., 1., 1.]`, which signals the end of an episode. One could then, for example, calculate the return for this first episode. We use a `for` loop to illustrate below, though faster approaches can be taken, of course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward at 0th step: [[0. 0. 0.]]\n",
            "Reward at 1th step: [[0. 0. 0.]]\n",
            "Reward at 2th step: [[0. 0. 0.]]\n",
            "Reward at 3th step: [[0. 0. 0.]]\n",
            "Reward at 4th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 5th step: [[0.98630136 0.98630136 0.98630136]]\n",
            "Reward at 6th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 7th step: [[0.65753424 0.65753424 0.65753424]]\n",
            "Reward at 8th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 9th step: [[0.65753424 0.65753424 0.65753424]]\n",
            "Reward at 10th step: [[0.7123288 0.7123288 0.7123288]]\n",
            "Reward at 11th step: [[0.65753424 0.65753424 0.65753424]]\n",
            "Reward at 12th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 13th step: [[0.65753424 0.65753424 0.65753424]]\n",
            "Reward at 14th step: [[1.0410959 1.0410959 1.0410959]]\n",
            "Reward at 15th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 16th step: [[0.98630136 0.98630136 0.98630136]]\n",
            "Reward at 17th step: [[0.32876712 0.32876712 0.32876712]]\n",
            "Reward at 18th step: [[0. 0. 0.]]\n",
            "Reward at 19th step: [[11.671233 11.671233 11.671233]]\n",
            "Episode return: [[20. 20. 20.]]\n"
          ]
        }
      ],
      "source": [
        "returns = jnp.zeros_like(offline_data['rewards'][:, 0, ...])\n",
        "for t in range(offline_data['rewards'].shape[1]):\n",
        "    reward = offline_data['rewards'][:, t, ...]\n",
        "    print(f\"Reward at {t}th step: {reward}\")\n",
        "    returns += reward\n",
        "    terminal_flag = offline_data['terminals'][:, t, ...]\n",
        "    if terminal_flag.all():\n",
        "        break\n",
        "print(f\"Episode return: {returns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also inspect a single timestep easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8d-NUj3LGnK",
        "outputId": "daf107aa-cd95-4ce2-bff8-908c0c5f56ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'actions': Array([[6, 0, 6]], dtype=int32),\n",
              " 'infos': {'legals': Array([[[0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "          [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "          [0., 1., 1., 1., 1., 1., 1., 0., 0.]]], dtype=float32),\n",
              "  'state': Array([[ 0.2       ,  0.        , -0.04060582,  0.05044992,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.2       ,  0.        ,\n",
              "          -0.06469727,  0.        ,  0.06666667,  0.11004639,  0.002485  ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ]], dtype=float32)},\n",
              " 'observations': Array([[[ 1.        ,  1.        ,  1.        ,  1.        ,\n",
              "           1.        ,  0.4918776 ,  0.46869576, -0.14922418,\n",
              "           0.06666667,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           1.        ,  0.17393287, -0.07495117, -0.1569553 ,\n",
              "           0.2       ,  0.2       ],\n",
              "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
              "           1.        ,  0.5437019 ,  0.54364693,  0.00773112,\n",
              "           0.06666667,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.        ,  0.        ,  1.        ,\n",
              "           0.17393287,  0.07495117,  0.1569553 ,  0.2       ,\n",
              "           0.        ,  0.        ,  0.        ,  0.        ,\n",
              "           0.        ,  0.2       ]]], dtype=float32),\n",
              " 'rewards': Array([[11.671233, 11.671233, 11.671233]], dtype=float32),\n",
              " 'terminals': Array([[1., 1., 1.]], dtype=float32),\n",
              " 'truncations': Array([[0., 0., 0.]], dtype=float32)}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.tree_map(lambda x: x[:, 19, ...], offline_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can easily use the Vault data as above, but Flashbax itself adds additional layers of convenient functionality. Here, we create a set of pure buffer functions, which we can use with the read data. Specifically, we sample a batch from the offline data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9TJ0NF8LX-S",
        "outputId": "65f14eca-3b97-4240-e3bd-ea56f769faf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/callum/miniconda3/envs/ogmarl/lib/python3.9/site-packages/flashbax/buffers/trajectory_buffer.py:498: UserWarning: `sample_sequence_length` greater than `min_length_time_axis`, therefore overriding `min_length_time_axis`to be set to `sample_sequence_length`, as we need at least `sample_sequence_length` timesteps added to the buffer before we can sample.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'actions': (32, 20, 3),\n",
              " 'infos': {'legals': (32, 20, 3, 9), 'state': (32, 20, 48)},\n",
              " 'observations': (32, 20, 3, 30),\n",
              " 'rewards': (32, 20, 3),\n",
              " 'terminals': (32, 20, 3),\n",
              " 'truncations': (32, 20, 3)}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "buffer = fbx.make_trajectory_buffer(\n",
        "    # Sampling parameters\n",
        "    sample_batch_size=BATCH_SIZE,\n",
        "    sample_sequence_length=SEQUENCE_LENGTH,\n",
        "    period=1,\n",
        "    # Not important in this example, as we are not adding to the buffer\n",
        "    max_length_time_axis=1_000_000,\n",
        "    min_length_time_axis=SEQUENCE_LENGTH,\n",
        "    add_batch_size=1,\n",
        ")\n",
        "\n",
        "buffer_sample = jax.jit(buffer.sample)\n",
        "seed = 0\n",
        "key = jax.random.PRNGKey(seed)\n",
        "\n",
        "samples = buffer_sample(all_data, key)\n",
        "\n",
        "jax.tree_map(lambda x: x.shape, samples.experience)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the shape of this data, `(BATCH_SIZE, SEQUENCE_LENGTH, ...)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Though Vaults have tight integration with a JAX-oriented ecosystem (using Flashbax etc.), it is trivial to read in the dataset and convert to your array-type of choice. For example, vanilla numpy or tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRD6IhZHMcHp",
        "outputId": "9d51791e-d9b2-480e-f5bb-819ded466d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'actions': array([[[4, 2, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        ...,\n",
            "        [2, 7, 2],\n",
            "        [2, 7, 2],\n",
            "        [2, 7, 2]]], dtype=int32), 'infos': {'legals': array([[[[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]]]], dtype=float32), 'state': array([[[ 1.        ,  0.        , -0.25      , ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 1.        ,  0.        , -0.20982143, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 1.        ,  0.        , -0.16964285, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ]]], dtype=float32)}, 'observations': array([[[[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.125     ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.125     ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.125     ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.125     ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.08013238,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.17564562,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.17564562,\n",
            "           0.2       ,  0.06666667]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.07921007,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.05200195,\n",
            "           0.06666667,  0.06666667],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.05200195,\n",
            "           0.06666667,  0.06666667]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.07912869,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.07291666,\n",
            "           0.06666667,  0.06666667],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.07291666,\n",
            "           0.06666667,  0.06666667]]]], dtype=float32), 'rewards': array([[[ 0.        ,  0.        ,  0.        ],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.32876712,  0.32876712,  0.32876712],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        [11.671233  , 11.671233  , 11.671233  ]]], dtype=float32), 'terminals': array([[[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [1., 1., 1.]]], dtype=float32), 'truncations': array([[[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]]], dtype=float32)}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "all_data_np = jax.tree_map(lambda x: np.array(x), all_data)\n",
        "\n",
        "print(all_data_np.experience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwawIQSuM-Fq",
        "outputId": "11e7c5db-711c-4646-cc8e-226974b3805b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'actions': <tf.Tensor: shape=(1, 996366, 3), dtype=int32, numpy=\n",
            "array([[[4, 2, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        ...,\n",
            "        [2, 7, 2],\n",
            "        [2, 7, 2],\n",
            "        [2, 7, 2]]], dtype=int32)>, 'infos': {'legals': <tf.Tensor: shape=(1, 996366, 3, 9), dtype=float32, numpy=\n",
            "array([[[[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.],\n",
            "         [0., 1., 1., ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]],\n",
            "\n",
            "        [[0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.],\n",
            "         [0., 1., 1., ..., 0., 1., 0.]]]], dtype=float32)>, 'state': <tf.Tensor: shape=(1, 996366, 48), dtype=float32, numpy=\n",
            "array([[[ 1.        ,  0.        , -0.25      , ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 1.        ,  0.        , -0.20982143, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 1.        ,  0.        , -0.16964285, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ],\n",
            "        [ 0.2       ,  0.        , -0.04910714, ...,  0.        ,\n",
            "          0.        ,  0.        ]]], dtype=float32)>}, 'observations': <tf.Tensor: shape=(1, 996366, 3, 30), dtype=float32, numpy=\n",
            "array([[[[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.125     ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.125     ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.0764974 ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.125     ,\n",
            "           1.        ,  1.        ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.125     ,\n",
            "           1.        ,  1.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.08013238,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.17564562,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.17564562,\n",
            "           0.2       ,  0.06666667]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.07921007,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.05200195,\n",
            "           0.06666667,  0.06666667],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.05200195,\n",
            "           0.06666667,  0.06666667]],\n",
            "\n",
            "        [[ 1.        ,  1.        ,  1.        , ...,  0.07912869,\n",
            "           0.06666667,  0.2       ],\n",
            "         [ 1.        ,  1.        ,  1.        , ...,  0.07291666,\n",
            "           0.06666667,  0.06666667],\n",
            "         [ 1.        ,  1.        ,  1.        , ..., -0.07291666,\n",
            "           0.06666667,  0.06666667]]]], dtype=float32)>, 'rewards': <tf.Tensor: shape=(1, 996366, 3), dtype=float32, numpy=\n",
            "array([[[ 0.        ,  0.        ,  0.        ],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.32876712,  0.32876712,  0.32876712],\n",
            "        [ 0.        ,  0.        ,  0.        ],\n",
            "        [11.671233  , 11.671233  , 11.671233  ]]], dtype=float32)>, 'terminals': <tf.Tensor: shape=(1, 996366, 3), dtype=float32, numpy=\n",
            "array([[[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [1., 1., 1.]]], dtype=float32)>, 'truncations': <tf.Tensor: shape=(1, 996366, 3), dtype=float32, numpy=\n",
            "array([[[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]]], dtype=float32)>}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "all_data_tf = jax.tree_map(lambda x: tf.convert_to_tensor(x), all_data)\n",
        "\n",
        "print(all_data_tf.experience)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the above code is independent of OG-MARL itself. This emphasises that the data from Vaults is not locked into our ecosystem. Nonetheless, OG-MARL provides many additional layers of useful, tightly integrated functionality. For example, we can easily analyse the distribution of the returns in a given vault."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install git+https://github.com/instadeepai/og-marl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from og_marl.offline_dataset import analyse_vault\n",
        "\n",
        "episode_returns = analyse_vault(\"3m.vlt\", visualise=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
